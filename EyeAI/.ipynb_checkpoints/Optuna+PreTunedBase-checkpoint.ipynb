{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c4dba4-c5f0-401e-858b-bb6f28be432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2849a70-00fa-4b59-908b-fb0c786162e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564ebcd4-bf22-48e7-8634-71e90446eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "label_to_idx = {\n",
    "    'normal':0,\n",
    "    'diabetic_retinopathy':1,\n",
    "    'glaucoma':2,\n",
    "    'cataract':3,\n",
    "}\n",
    "idx_to_label = {\n",
    "    0:'normal',\n",
    "    1:\"diabetic_retinopathy\",\n",
    "    2:'glaucoma',\n",
    "    3:'cataract'\n",
    "}\n",
    "for class_name in os.listdir(\"dataset\"):\n",
    "    img_paths = os.listdir(f'dataset/{class_name}')\n",
    "    for img_path in img_paths:\n",
    "        paths.append((label_to_idx[class_name], os.path.join(\"dataset\",class_name,img_path)))\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, paths_list, transform = None):\n",
    "        super().__init__()\n",
    "        self.path_list = paths_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        class_idx, img_path = self.path_list[idx]\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                return class_idx, img\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}:{str(e)}\")\n",
    "            return None\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((224,224))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d877dd2c-9bb7-4913-9061-fe08cfc28b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [item[0] for item in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05dd1bb-0845-4460-b5fa-f0679c0dcb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, test_paths = train_test_split(paths, stratify = labels, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "241e3dda-15cc-4151-ac59-d2a404225598",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_paths, transform = transform)\n",
    "test_dataset = CustomDataset(test_paths, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952ce1c5-030e-4400-a9ef-4c7823d84025",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(weights='VGG16_Weights.IMAGENET1K_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc52fdda-70e8-47ce-97c0-b9909bec625e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0a7d00-2208-4d89-ae58-fa3e725fe89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_hidden_layers=3, neurons_per_layer=4096, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = vgg16.features\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\n",
    "        layers = []\n",
    "        inp_dim = 512*7*7\n",
    "\n",
    "        if num_hidden_layers >= 1:\n",
    "            layers.extend([\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(inp_dim,4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            inp_dim = 4096\n",
    "\n",
    "        for _ in range(1, num_hidden_layers):\n",
    "            layers.extend([\n",
    "                nn.Linear(inp_dim,neurons_per_layer),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            inp_dim = neurons_per_layer\n",
    "            \n",
    "        layers.append(nn.Linear(inp_dim,4))\n",
    "\n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.features(X)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87787421-6e42-4f74-89e4-2bf89961474b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.4, inplace=False)\n",
       "    (7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.4, inplace=False)\n",
       "    (10): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def objective(trial):\n",
    "# epochs = trial.suggest_int(\"epochs\", 3,10)\n",
    "# num_hidden_layers = trial.suggest_int('num_hidden_layers', 1,3, step = 1)\n",
    "# neurons_per_layer = trial.suggest_categorical('neurons_per_layer', [512, 1024, 2048, 4096])\n",
    "# lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log = True)\n",
    "# dropout_rate = trial.suggest_float('dropout_rate', 0.1,0.7, step = 0.1)\n",
    "# batch_size = trial.suggest_categorical('batch_size', [8,16,32,64,128])\n",
    "# weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log = True)\n",
    "# opt = trial.suggest_categorical('opt',['adam','sgd'])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size = 128, shuffle = True, pin_memory = True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size = 128, shuffle = False, pin_memory = True)\n",
    "\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# if opt == \"adam\":\n",
    "# optimizer = optim.Adam(model.classifier.parameters(), lr = 0.0006196910851444527, weight_decay = 0.00015375266336036664)\n",
    "# # else:\n",
    "#     # optimizer = optim.SGD(model.classifier.parameters(), lr = lr, weight_decay = weight_decay, momentum = 0.9)\n",
    "# epochs = 4\n",
    "# for epoch in range(epochs):\n",
    "#     total_epoch_loss = 0\n",
    "#     for batch_labels,batch_features in train_loader:\n",
    "#         batch_labels = batch_labels.to(device)\n",
    "#         batch_features =  batch_features.to(device)\n",
    "\n",
    "#         outputs = model(batch_features)\n",
    "#         loss = loss_fn(outputs,batch_labels)\n",
    "#         total_epoch_loss += loss.item()\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     avg_epoch_loss = total_epoch_loss/len(train_loader)\n",
    "#     print(f\"Epoch:{epoch+1}, Loss:{avg_epoch_loss}\")\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# total = 0\n",
    "# correct = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch_labels,batch_features in test_loader:\n",
    "#         batch_labels = batch_labels.to(device)\n",
    "#         batch_features =  batch_features.to(device)\n",
    "\n",
    "#         outputs = model(batch_features)\n",
    "#         _, y_pred = torch.max(outputs, 1)\n",
    "#         total += batch_labels.shape[0]\n",
    "#         correct += (batch_labels == y_pred).sum().item()\n",
    "        \n",
    "#     accuracy = correct/total\n",
    "\n",
    "# return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ed23b-23f2-492a-b7b0-a81849ba90e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(\n",
    "#     direction = \"maximize\",\n",
    "#     sampler = optuna.samplers.TPESampler(),\n",
    "#     pruner = optuna.pruners.MedianPruner()\n",
    "# )\n",
    "# study.optimize(objective, n_trials = 50) # CHange n_trials to 50 for final execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41a105-4723-4c0d-881d-29d5dd483e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd07667-f2a5-46f8-92a2-1d2d5ae51027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a76e67-1106-46db-8f09-be5e7c4ade04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ead75f-4b9e-4bc4-890c-04bfef15ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best trial:\n",
    "# Value: 0.9014218009478673\n",
    "# Params:\n",
    "# epochs:5\n",
    "# num_hidden_layers:3\n",
    "# neurons_per_layer:4096\n",
    "# lr:0.0006196910851444527\n",
    "# dropout_rate:0.4\n",
    "# batch_size:128\n",
    "# weight_decay:0.00015375266336036664\n",
    "# opt:adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7263af-c8a5-4987-b346-8adf643d49d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value: 0.9014218009478673\n",
      "Params:\n",
      "epochs:5\n",
      "num_hidden_layers:3\n",
      "neurons_per_layer:4096\n",
      "lr:0.0006196910851444527\n",
      "dropout_rate:0.4\n",
      "batch_size:128\n",
      "weight_decay:0.00015375266336036664\n",
      "opt:adam\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\visualization\\_plotly_imports.py:7\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m try_import() \u001b[38;5;28;01mas\u001b[39;00m _imports:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m plotly_version\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Visualize\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43moptuna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_optimization_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\visualization\\_optimization_history.py:200\u001b[0m, in \u001b[0;36mplot_optimization_history\u001b[1;34m(study, target, target_name, error_bar)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_optimization_history\u001b[39m(\n\u001b[0;32m    173\u001b[0m     study: Study \u001b[38;5;241m|\u001b[39m Sequence[Study],\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m     error_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    178\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgo.Figure\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot optimization history of all trials in a study.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m \n\u001b[0;32m    181\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m        A :class:`plotly.graph_objects.Figure` object.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     \u001b[43m_imports\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     info_list \u001b[38;5;241m=\u001b[39m _get_optimization_history_info_list(study, target, target_name, error_bar)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_optimization_history_plot(info_list, target_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\_imports.py:94\u001b[0m, in \u001b[0;36m_DeferredImportExceptionContextManager.check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     exc_value, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deferred\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc_value\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "#execute after study is done\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"Value: {trial.value}\")\n",
    "print(\"Params:\")\n",
    "for k,v in trial.params.items():\n",
    "    print(f\"{k}:{v}\")\n",
    "\n",
    "# Visualize\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b52108f-075c-404a-a3b7-7ea4e20ba4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.9247311827956989\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "#87,91\n",
    "with torch.no_grad():\n",
    "    for batch_labels,batch_features in train_loader:\n",
    "        batch_features,batch_labels = batch_features.to(device),batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, y_pred = torch.max(outputs, 1)\n",
    "        total += batch_labels.shape[0]\n",
    "        correct += (batch_labels == y_pred).sum().item()\n",
    "print(\"train: \",correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f75ff21a-6cda-4e1c-877e-c35f79b9196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.8530805687203792\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_labels,batch_features in test_loader:\n",
    "        batch_features,batch_labels = batch_features.to(device),batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        _, y_pred = torch.max(outputs, 1)\n",
    "        total += batch_labels.shape[0]\n",
    "        correct += (batch_labels == y_pred).sum().item()\n",
    "print(\"test: \",correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "716eba7d-de9b-4f54-becf-721f2b896378",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"label_to_idx\": label_to_idx,\n",
    "    \"idx_to_label\":idx_to_label,\n",
    "    \"input_size\": (3,224,224) #Change this as input size defined in CNN definition most probably (3,224,224) if using vgg as pre trained base\n",
    "}, \"fundus_classifier(test-89.38, train-96.74).pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12db11fa-77d2-4f6c-b8be-73fcedb62557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('fundus_classifier(test-89.38, train-96.74).pth', map_location = device)\n",
    "\n",
    "checkpoint = torch.load('fundus_classifier(test-89.38, train-96.74).pth')\n",
    "\n",
    "model = CNN()  # Make sure CNN matches the model architecture you trained\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  # âœ… Correct key\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Also extract label mappings if needed:\n",
    "idx_to_label = checkpoint['idx_to_label']\n",
    "label_to_idx = checkpoint['label_to_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ef70e1-82f0-45ad-859a-21130058e624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.4, inplace=False)\n",
       "    (7): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (8): ReLU()\n",
       "    (9): Dropout(p=0.4, inplace=False)\n",
       "    (10): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "383db78b-9346-4e10-b836-36b7f996eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(image_path, idx_to_label, model):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = transform(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    \n",
    "    logits = model(img)\n",
    "    probabilities = F.softmax(logits, dim =1)\n",
    "    prob, prediction = torch.max(probabilities, dim=1)\n",
    "    return float(prob), idx_to_label[int(prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4b04800-d739-40dc-9750-5d1316e8e496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9891865849494934, 'glaucoma')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "do_inference('dataset/glaucoma/_10_1472170.jpg', idx_to_label, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d5f49-5424-4892-aa66-dd1799daa4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
